{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e88696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../commons/imports_cleaner.ipynb\n",
    "%run ../commons/helper_db.ipynb\n",
    "%run ../commons/helper_contents.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a270d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL CONFIGS\n",
    "create_database('blp_dataset')\n",
    "\n",
    "cursor = conn.cursor(buffered=True)\n",
    "\n",
    "DB_NAME = \"blp_dataset\"\n",
    "TABLE_NAME = \"products_tmp_amazon\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc2101",
   "metadata": {},
   "source": [
    "## First step: clear all repeated images\n",
    "\n",
    "Using Perceptual Hashing (P-Hash) algorithm, we analyze and remove all images that have equal hashes.\n",
    "We also updated the database, so we can have control over how the Dark Marketplace (DM) data was distributed. This can also help with future work.\n",
    "\n",
    "Database fields that do not have a valid image will not be used in the training. We will only use those products that have both description and title as well as image, and vice versa, in order to maintain a balance between the results of the two networks.\n",
    "\n",
    "Keeping the lines in the database that have no image, just placing a flag to indicate the status, we open the possibility of using this data in training, if necessary.\n",
    "\n",
    "Also, we will copy the images that are not repeated, but has the texts into this situation, so we can use those files if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03208d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAR REPEATED IMAGES\n",
    "MAIN_FOLDER = r\"D:\\images\\_amazon\"\n",
    "folder = Path(MAIN_FOLDER)\n",
    "p_img_hashes = {}\n",
    "error_files = []\n",
    "\n",
    "for image in os.listdir(folder):\n",
    "    image_path = Path(f\"{folder}\\{image}\")\n",
    "\n",
    "    try:\n",
    "        hash = imagehash.phash(Image.open(image_path))\n",
    "        image_name = os.path.splitext(image)[0]\n",
    "\n",
    "        if hash in p_img_hashes:\n",
    "            os.remove(image_path)\n",
    "        else:\n",
    "            p_img_hashes[hash] = image\n",
    "    except:\n",
    "        error_files.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_image(image_path):\n",
    "    os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9336b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_image(name):\n",
    "    url_image = Path(f\"{Path(MAIN_FOLDER)}\\{name}.jpeg\")\n",
    "    dst_dir = Path(f\"D:\\images\\excluded_product\\{name}.jpeg\")\n",
    "\n",
    "    if url_image.exists():\n",
    "        copyfile(url_image, dst_dir)\n",
    "        del_image(url_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f002b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAR REPEATED TEXTS\n",
    "cursor.execute(\n",
    "    \"SELECT description, COUNT(description) \"\n",
    "    \"FROM products_tmp_amazon \"\n",
    "    \"GROUP BY description HAVING COUNT(description) > 1\")\n",
    "\n",
    "repeated = cursor.fetchall()\n",
    "\n",
    "for res in repeated:\n",
    "    cursor.execute(\"SELECT id FROM \" + TABLE_NAME + \" WHERE description = %s\", (res[0],))\n",
    "    to_clear = cursor.fetchall()\n",
    "    cont = 0\n",
    "\n",
    "    for item in to_clear:\n",
    "        if cont > 0:\n",
    "            print(f\"Product {item[0]}\")\n",
    "\n",
    "            cursor.execute(\"DELETE FROM \" + TABLE_NAME + \" WHERE id = %s\", (item[0],))\n",
    "            conn.commit()\n",
    "        else:\n",
    "            print(f\"Product {item[0]} saved\")\n",
    "        cont = cont + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3a142",
   "metadata": {},
   "source": [
    "## Next step: join the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef58d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT id, name, description, market_name, seller_name, illegal FROM products_tmp_oxygen\")\n",
    "items = cursor.fetchall()\n",
    "\n",
    "DEST_FOLDER = r\"D:\\images\\illegal\"\n",
    "dest = Path(DEST_FOLDER)\n",
    "\n",
    "error = []\n",
    "\n",
    "for i in items:\n",
    "    query = \"INSERT INTO products (name, description, market_name, seller_name, illegal) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    values = (i[1], i[2], i[3], i[4], \"t\")\n",
    "\n",
    "    cursor.execute(query, values)\n",
    "    conn.commit()\n",
    "#     product_id = cursor.lastrowid\n",
    "\n",
    "#     url_image = Path(f\"{Path(MAIN_FOLDER)}\\{i[0]}.jpeg\")\n",
    "#     dst_dir = Path(f\"{Path(dest)}\\{product_id}.jpeg\")\n",
    "\n",
    "#     if url_image.exists():\n",
    "#         copyfile(url_image, dst_dir)\n",
    "#         del_image(url_image)\n",
    "        \n",
    "#     else:\n",
    "#         error.append(i[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
